{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "import copy\n",
    "import dateutil.parser\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind, mannwhitneyu, kruskal, ks_2samp\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import location\n",
    "from utils import Utils\n",
    "from tweet import Tweet\n",
    "from video import Video\n",
    "\n",
    "## [abo | gun | blm]\n",
    "campaign = 'abo'\n",
    "\n",
    "bin_size = 7\n",
    "connection_type = 'followers'\n",
    "year = 2018\n",
    "\n",
    "util = Utils(campaign, bin_size, connection_type, year)\n",
    "\n",
    "tweet = Tweet(util)\n",
    "video = Video(util)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create available early adopters, their tweets, locations, political leanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_tweets = tweet.getAvailableTweets(0.2)\n",
    "print('#tweets by available early adopters: {}'.format(len(ea_tweets.keys())))\n",
    "\n",
    "ea_tweets_counts = tweet.getTweetVolumeDistribution(ea_tweets)\n",
    "util.plotLineChart(ea_tweets_counts, \"# of tweets\", \"Weeks\")\n",
    "\n",
    "# Sort tweet counts by weekly\n",
    "# ea_tweets_counts_sorted_ind, dates_sorted = util.sortVolumeByDate(ea_tweets_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for tweet-video-user analysis\n",
    "\n",
    "# Analysis of videos by tweet volume within a specific date\n",
    "# tweet.sortVideosByTweetVolumeForSpecificInterval(ea_tweets, '2018-04-15', '2018-04-22')\n",
    "\n",
    "# Print tweets that refer to specific video within a specific week\n",
    "# tweet.printTweetsByVideoId(ea_tweets, '2017-01-01', '2018-05-01', 'Rw9E_nGVXxA')\n",
    "\n",
    "# Analyze tweets of most-tweeted user.\n",
    "# tweet.analyzeTweetsOfMostTweetedUsers(ea_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find early adopters' locations\n",
    "\n",
    "# tweet.assignUserLocations(ea_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find political leanings of seed early adopters.\n",
    "\n",
    "# First find occurrence of hashtags (potential ones for expansion) with seed political hashtags. \n",
    "# hashtags, ht_occur_vec, cooccur_mat = tweet.findHashtagCooccurrences()\n",
    "\n",
    "# Then, manually analyze these hashtags, and decide which hashtags to select for political leaning expansion.\n",
    "# Create 'left_political_hashtags_extended.txt' and 'right_political_hashtags_extended.txt' manually.\n",
    "\n",
    "# Based on extended political hashtags, assign political labels to seed early adopters.\n",
    "# leaning_labels = tweet.assignUserLeaningLabels()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze how many users, their tweets (with types) and followers are there for early adopters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet.summarizeUsersTweetsInfo(ea_tweets)\n",
    "# tweet.summarizeFollowers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Community summarization\n",
    "# tweet.summarizeCommunities()\n",
    "\n",
    "## (Optional) check political leanings for each community.\n",
    "# predefined_community_leanings, inferred_community_leanings = tweet.checkLeaningsInCommunities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze tweet volume per video given a time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_ids = tweet.sortVideosByTweetVolumeForSpecificInterval(ea_tweets, '2017-01-01', '2018-05-01')\n",
    "# video_ids = [video_id[0] for video_id in video_ids]\n",
    "# print(len(video_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NW Structural, Engagement, Temporal, Language and Cascade Operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create sub_followings_dict once to make the cascade computation cost efficient.\n",
    "# tweet.createSubFollowingsDictForCascade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NW Structural Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate structural measures for each video in filtered video set.\n",
    "# structural_measures = tweet.getAllNetworkStructureMeasures(ea_tweets)\n",
    "\n",
    "## Anaylze structural measures for each video in filtered video set.\n",
    "# measure_type = 'nw_size'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeStructuralMeasures(measure_type, video_leanings_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate engagement measures for each video in filtered video set.\n",
    "# engagement_measures = tweet.getAllEngagementMeasures(ea_tweets)\n",
    "\n",
    "## Anaylze engagement measures for each video in filtered video set.\n",
    "# measure_type = 'num_replies'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeEngagementMeasures(measure_type, video_leanings_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate temporal measures for each video in filtered video set.\n",
    "# temporal_measures = tweet.getAllTemporalMeasures(ea_tweets)\n",
    "\n",
    "## Anaylze temporal measures for each video in filtered video set.\n",
    "# measure_type = 'nw_temporal_diff_between_max_indegree_user'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeTemporalMeasures(measure_type, video_leanings_probs)\n",
    "\n",
    "## This is an analysis for a given video.\n",
    "#nw_temporal_diff_wrt_first_tweet_mean, nw_temporal_diff_wrt_first_tweet_median, nw_temporal_diff_between_pairs_mean, nw_diff_speed_mnw_temporal_diff_between_pairs_median, nw_life_time, nw_temporal_diff_between_first_tweets_of_source_users_mean, nw_temporal_diff_between_first_tweets_of_source_users_median, nw_temporal_diff_between_max_indegree_user = tweet.getTemporalMeasuresByVideoId(ea_tweets, 'Iqc4BrAzDio')\n",
    "#print(nw_temporal_diff_wrt_first_tweet_mean, nw_temporal_diff_wrt_first_tweet_median, nw_temporal_diff_between_pairs_mean, nw_diff_speed_mnw_temporal_diff_between_pairs_median, nw_life_time, nw_temporal_diff_between_first_tweets_of_source_users_mean, nw_temporal_diff_between_first_tweets_of_source_users_median, nw_temporal_diff_between_max_indegree_user)\n",
    "#'lpskBk0fp4o'\n",
    "#'Iqc4BrAzDio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate language measures for each video in filtered video set.\n",
    "# language_liwc_measures, language_empath_measures = tweet.getAllLanguageMeasures(ea_tweets)\n",
    "\n",
    "## Anaylze language measures for each video in filtered video set.\n",
    "## dict_type: [liwc | empath]\n",
    "# dict_type = 'liwc'\n",
    "# measure_type = 'p2'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeLanguageMeasures(dict_type, measure_type, video_leanings_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anaylze language measures for each video in filtered video set.\n",
    "# leaning = 'right'\n",
    "# dict_type = 'liwc'\n",
    "# measure_type = 'negate'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeTweetsByLanguageCategory(dict_type, measure_type, video_leanings_probs, ea_tweets, leaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Calculate cascade for each video in filtered video set.\n",
    "# cascades = tweet.getAllTweetCascades(ea_tweets)\n",
    "\n",
    "## Anaylze cascades\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# tweet.analyzeCascadeMeasures(video_leanings_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YT Reaction Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Analyze YT Reaction measures.\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# video_measures = tweet.analyzeDivisiveContentsByScatterPlots(video_leanings_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YT Raw Measures comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Analyze YT raw measures.\n",
    "# measure_type = 'duration'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# video_measures = tweet.analyzeVideosByProperty(video_leanings_probs, measure_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YT Raw Measures (Normalized) comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Analyze YT raw (normalized) measures.\n",
    "# measure_type = 'dislikeCount'\n",
    "# video_leanings_probs = tweet.assignVideoLeaningLabels(ea_tweets)\n",
    "# video_measures = tweet.analyzeVideosByNormalizedProperty(video_leanings_probs, measure_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other helper functions from Utils to create annotation files for Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.createCandidateVideosFile()\n",
    "# util.createVideosFileForManualAnnotations()\n",
    "# util.createVideosFileForManualAnnotationsUsingSubtitles()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
