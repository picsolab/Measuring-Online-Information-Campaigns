{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import community\n",
    "from operator import itemgetter\n",
    "from scipy import integrate\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "## [abo | gun | blm]\n",
    "campaign = 'blm'\n",
    "## [followers | friends]\n",
    "connection_type = 'followers'\n",
    "## [2018 | 2020]\n",
    "year = 2018\n",
    "\n",
    "\n",
    "## Read the connection list\n",
    "connection_list = pickle.load(open(\"data/social_media/{}/ea_{}_{}.pkl\".format(campaign, connection_type, str(year)), 'rb'))\n",
    "print(\"{} list read!\".format(connection_type))\n",
    "\n",
    "## Read the connection graph\n",
    "filtered_graph_file_path = 'data/social_media/{}/graph_edges/ea_filtered_graph_edge_list_{}.gpickle'.format(campaign, str(year))\n",
    "G = nx.read_gpickle(filtered_graph_file_path)\n",
    "print('Filtered G read!')\n",
    "print(\"# of nodes in G:\", G.number_of_nodes())\n",
    "print(\"# of edges in G:\", G.number_of_edges())\n",
    "\n",
    "'''\n",
    "## Add the nodes not having any common followers to the graph.\n",
    "diff_users = list(set(connection_list.keys()).difference(set(G.nodes)))\n",
    "print(\"# of diff users:\", len(diff_users))\n",
    "for user in diff_users:\n",
    "    G.add_node(user)\n",
    "\n",
    "print(\"# of nodes in G after addition:\", G.number_of_nodes())\n",
    "print(\"# of edges in G after addition:\", G.number_of_edges())\n",
    "'''\n",
    "\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "print(\"# of nodes in G after removal of isolates:\", G.number_of_nodes())\n",
    "print(\"# of edges in G after removal of isolates:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(G.nodes)\n",
    "print(\"len(node_list):\", len(node_list))\n",
    "\n",
    "users_leanings = pickle.load(open('data/from_anu/v1/{}_{}_users_leanings_labels.pkl'.format(campaign, ea_type), 'rb'))\n",
    "labeled_users = [user_id for user_id in users_leanings if users_leanings[user_id] != -1 and user_id in node_list]\n",
    "unlabeled_users = [user_id for user_id in users_leanings if users_leanings[user_id] == -1 and user_id in node_list]\n",
    "all_users = labeled_users + unlabeled_users\n",
    "print('len(all_users):', len(all_users))\n",
    "\n",
    "labeled_labels = [users_leanings[user_id] for user_id in labeled_users]\n",
    "print('len(labeled_users):', len(labeled_users))\n",
    "print('len(labeled_labels):', len(labeled_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First apply 10-fold CV to see the label propagation works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = []\n",
    "true_labels = []\n",
    "skf = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "for train_index, test_index in skf.split(labeled_users, labeled_labels):\n",
    "    fold_train_labeled_users = list(itemgetter(*train_index)(labeled_users))\n",
    "    aa = list(itemgetter(*list(train_index))(labeled_users))\n",
    "    fold_train_labeled_labels = list(itemgetter(*train_index)(labeled_labels))\n",
    "    fold_test_labeled_users = list(itemgetter(*test_index)(labeled_users))\n",
    "    fold_test_labeled_labels = list(itemgetter(*test_index)(labeled_labels))\n",
    "        \n",
    "    fold_all_users = fold_train_labeled_users + fold_test_labeled_users + unlabeled_users\n",
    "    fold_init_labels = np.zeros(shape=(len(all_users), 2))\n",
    "    print(len(fold_all_users), len(all_users))\n",
    "    \n",
    "    for i in range(len(fold_train_labeled_users)):\n",
    "        fold_init_labels[i][users_leanings[fold_train_labeled_users[i]]] = 1.\n",
    "    \n",
    "    W_fold = nx.convert_matrix.to_numpy_matrix(G, nodelist=fold_all_users)\n",
    "    print(W_fold.shape, np.sum(W_fold))\n",
    "    \n",
    "    ## Apply label propagation by paulmorio\n",
    "    alpha = 0.85\n",
    "    mu = (1/alpha) - 1\n",
    "    beta = mu/(1+mu)\n",
    "    D_fold = (np.power(np.sum(W_fold, 1), -0.5))\n",
    "    D_fold = np.squeeze(np.asarray(D_fold))\n",
    "    D_fold = np.diag(D_fold)\n",
    "    S_fold = D_fold*W_fold*D_fold\n",
    "\n",
    "    #predictions_score_fold = copy.deepcopy(fold_init_labels)\n",
    "    \n",
    "    ## Instead of propagation without regularization\n",
    "    #predictions_score_fold = (np.linalg.inv(np.identity(W_fold.shape[0]) - alpha*S_fold)) * predictions_score_fold\n",
    "    #predictions_score_fold = (np.linalg.inv(np.identity(W_fold.shape[0]) - alpha*S_fold)) * fold_init_labels\n",
    "    \n",
    "    ## Instead of propagation with regularization\n",
    "    #predictions_score_fold = beta*(np.linalg.inv(np.identity(W_fold.shape[0]) - alpha*S_fold)) * predictions_score_fold\n",
    "    predictions_score_fold = beta*(np.linalg.inv(np.identity(W_fold.shape[0]) - alpha*S_fold)) * fold_init_labels\n",
    "    \n",
    "    for i in range(len(fold_train_labeled_users), len(labeled_labels)):\n",
    "        pred_results.append(np.argmax(predictions_score_fold[i]))\n",
    "    \n",
    "    for i in range(len(fold_test_labeled_labels)):\n",
    "        true_labels.append(fold_test_labeled_labels[i])\n",
    "\n",
    "\n",
    "left = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "for i in range(len(pred_results)):\n",
    "    if pred_results[i] == true_labels[i]:\n",
    "        if pred_results[i] == 0 and true_labels[i] == 0:\n",
    "            left += 1\n",
    "        elif pred_results[i] == 1 and true_labels[i] == 1:\n",
    "            right += 1\n",
    "        counter += 1\n",
    "\n",
    "print('acc:', float(counter)/len(true_labels))\n",
    "print('left acc:', float(left)/len([a for a in labeled_labels if a == 0]))\n",
    "print('right acc:', float(right)/len([a for a in labeled_labels if a == 1]))\n",
    "print(len([a for a in labeled_labels if a == 0]))\n",
    "print(len([a for a in labeled_labels if a == 1]))\n",
    "\n",
    "print(classification_report(true_labels, pred_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, apply Label propagation on unknown users to assign labels and probs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_labels = np.zeros(shape=(len(all_users), 2))\n",
    "for i in range(len(labeled_users)):\n",
    "    init_labels[i][users_leanings[labeled_users[i]]] = 1. \n",
    "\n",
    "W = nx.convert_matrix.to_numpy_matrix(G, nodelist=all_users)\n",
    "print(W.shape, np.sum(W))\n",
    "\n",
    "alpha = 0.85\n",
    "mu = (1/alpha) - 1\n",
    "beta = mu/(1+mu)\n",
    "D = (np.power(np.sum(W, 1), -0.5))\n",
    "D = np.squeeze(np.asarray(D))\n",
    "D = np.diag(D)\n",
    "S = D*W*D\n",
    "\n",
    "## Instead of propagation with regularization\n",
    "predictions_score = beta*(np.linalg.inv(np.identity(W.shape[0]) - alpha*S)) * init_labels\n",
    "\n",
    "pred_results = np.asarray(predictions_score)\n",
    "pred_labels = np.argmax(np.asarray(predictions_score), axis=1)\n",
    "cnt = 0\n",
    "for i in range(pred_results.shape[0]):\n",
    "    if pred_results[i][0] == pred_results[i][1]:\n",
    "        pred_labels[i] = -1\n",
    "        cnt+=1\n",
    "print('#inferred equally: {}'.format(cnt))\n",
    "\n",
    "\n",
    "# Find labels for unknown users\n",
    "counter = 0\n",
    "for i in range(len(labeled_labels)):\n",
    "    if pred_labels[i] == labeled_labels[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(\"{} remained same!\".format(float(counter)/len(labeled_users)))\n",
    "\n",
    "# Find inferred scores for unkonwn users\n",
    "inferred_scores = {}\n",
    "for i in range(len(all_users)):\n",
    "    if users_leanings[all_users[i]] != -1:\n",
    "        if users_leanings[all_users[i]] == 0:\n",
    "            inferred_scores[all_users[i]] = {'left': 1, 'right': 0}\n",
    "        elif users_leanings[all_users[i]] == 1:\n",
    "            inferred_scores[all_users[i]] = {'left': 0, 'right': 1}\n",
    "    else:\n",
    "        inferred_scores[all_users[i]] = {'left': pred_results[i][0], 'right': pred_results[i][1]}\n",
    "\n",
    "\n",
    "diff_users = list(set(connection_list.keys()).difference(set(G.nodes)))\n",
    "for user_id in diff_users:\n",
    "    if users_leanings[user_id] == 0:\n",
    "        inferred_scores[user_id] = {'left': 1, 'right': 0}\n",
    "    elif users_leanings[user_id] == 1:\n",
    "        inferred_scores[user_id] = {'left': 0, 'right': 1}\n",
    "    elif users_leanings[user_id] == -1:\n",
    "        inferred_scores[user_id] = {'left': 0, 'right': 0}\n",
    "\n",
    "        \n",
    "pickle.dump(inferred_scores, open('data/social_media/{}/ea_users_inferred_leanings_scores.pkl'.format(campaign), 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
