{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "import copy\n",
    "import dateutil.parser\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind, mannwhitneyu, kruskal, ks_2samp\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import location\n",
    "from utils import Utils\n",
    "from tweet_ea import Tweet\n",
    "import re\n",
    "import pingouin as pg\n",
    "\n",
    "def exponent_fmt(x, pos):\n",
    "    \"\"\" The two args are the value and tick position. \"\"\"\n",
    "    return '$10^{{{0:.0f}}}$'.format(x)\n",
    "\n",
    "bin_size = 7\n",
    "connection_type = 'followers'\n",
    "year = 2018\n",
    "\n",
    "util_abo = Utils('abo', bin_size, connection_type, year)\n",
    "util_gun = Utils('gun', bin_size, connection_type, year)\n",
    "util_blm = Utils('blm', bin_size, connection_type, year)\n",
    "\n",
    "tweet_abo = Tweet(util_abo)\n",
    "tweet_gun = Tweet(util_gun)\n",
    "tweet_blm = Tweet(util_blm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_tweets_abo = tweet_abo.getAvailableTweets(0.2)\n",
    "print('ABO: {}'.format(len(ea_tweets_abo.keys())))\n",
    "\n",
    "ea_tweets_gun = tweet_gun.getAvailableTweets(0.2)\n",
    "print('GUN: {}'.format(len(ea_tweets_gun.keys())))\n",
    "\n",
    "ea_tweets_blm = tweet_blm.getAvailableTweets(0.2)\n",
    "print('BLM: {}'.format(len(ea_tweets_blm.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_leanings_probs_abo = tweet_abo.assignVideoLeaningLabels(ea_tweets_abo)\n",
    "vids_abo = tweet_abo.separateVideosByLeaning(video_leanings_probs_abo)\n",
    "print(\">>> ABO --> L: {}, N: {}, R: {}\".format(len(vids_abo['L']), len(vids_abo['N']), len(vids_abo['R'])))\n",
    "\n",
    "print(vids_abo)\n",
    "\n",
    "video_leanings_probs_gun = tweet_gun.assignVideoLeaningLabels(ea_tweets_gun)\n",
    "vids_gun = tweet_gun.separateVideosByLeaning(video_leanings_probs_gun)\n",
    "print(\">>> GUN --> L: {}, N: {}, R: {}\".format(len(vids_gun['L']), len(vids_gun['N']), len(vids_gun['R'])))\n",
    "\n",
    "video_leanings_probs_blm = tweet_blm.assignVideoLeaningLabels(ea_tweets_blm)\n",
    "vids_blm = tweet_blm.separateVideosByLeaning(video_leanings_probs_blm)\n",
    "print(\">>> BLM --> L: {}, N: {}, R: {}\".format(len(vids_blm['L']), len(vids_blm['N']), len(vids_blm['R'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRUCTURAL MEASURE OPERATIONS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structural_measures_abo = tweet_abo.getAllNetworkStructureMeasures(ea_tweets_abo)\n",
    "structural_measures_gun = tweet_gun.getAllNetworkStructureMeasures(ea_tweets_gun)\n",
    "structural_measures_blm = tweet_blm.getAllNetworkStructureMeasures(ea_tweets_blm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "measure_type = 'nw_density'\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "measures_left_abo = [structural_measures_abo[vid][measure_type] for vid in vids_abo['L'] if (structural_measures_abo[vid][measure_type] != None and not math.isnan(structural_measures_abo[vid][measure_type]) and not math.isinf(structural_measures_abo[vid][measure_type]))]\n",
    "measures_right_abo = [structural_measures_abo[vid][measure_type] for vid in vids_abo['R'] if (structural_measures_abo[vid][measure_type] != None and not math.isnan(structural_measures_abo[vid][measure_type]) and not math.isinf(structural_measures_abo[vid][measure_type]))]\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_abo, measures_right_abo))\n",
    "print(pg.mwu(measures_left_abo, measures_right_abo, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_abo), np.median(measures_left_abo)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_abo), np.median(measures_right_abo)))\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "measures_left_gun = [structural_measures_gun[vid][measure_type] for vid in vids_gun['L'] if (structural_measures_gun[vid][measure_type] != None and not math.isnan(structural_measures_gun[vid][measure_type]) and not math.isinf(structural_measures_gun[vid][measure_type]))]\n",
    "measures_right_gun = [structural_measures_gun[vid][measure_type] for vid in vids_gun['R'] if (structural_measures_gun[vid][measure_type] != None and not math.isnan(structural_measures_gun[vid][measure_type]) and not math.isinf(structural_measures_gun[vid][measure_type]))]\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_gun, measures_right_gun))\n",
    "print(pg.mwu(measures_left_gun, measures_right_gun, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_gun), np.median(measures_left_gun)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_gun), np.median(measures_right_gun)))\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "measures_left_blm = [structural_measures_blm[vid][measure_type] for vid in vids_blm['L'] if (structural_measures_blm[vid][measure_type] != None and not math.isnan(structural_measures_blm[vid][measure_type]) and not math.isinf(structural_measures_blm[vid][measure_type]))]\n",
    "measures_right_blm = [structural_measures_blm[vid][measure_type] for vid in vids_blm['R'] if (structural_measures_blm[vid][measure_type] != None and not math.isnan(structural_measures_blm[vid][measure_type]) and not math.isinf(structural_measures_blm[vid][measure_type]))]\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_blm, measures_right_blm))\n",
    "print(pg.mwu(measures_left_blm, measures_right_blm, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_blm), np.median(measures_left_blm)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_blm), np.median(measures_right_blm)))\n",
    "\n",
    "leanings = ['Left']*len(measures_left_abo) + ['Right']*len(measures_right_abo) + ['Left']*len(measures_left_gun) + ['Right']*len(measures_right_gun) + ['Left']*len(measures_left_blm) + ['Right']*len(measures_right_blm) \n",
    "topics = ['Abortion']*(len(measures_left_abo)+len(measures_right_abo)) + ['Gun control']*(len(measures_left_gun)+len(measures_right_gun)) + ['BLM']*(len(measures_left_blm)+len(measures_right_blm))\n",
    "measures = measures_left_abo + measures_right_abo + measures_left_gun + measures_right_gun + measures_left_blm + measures_right_blm\n",
    "\n",
    "\n",
    "if measure_type == 'nw_size' or measure_type == 'nw_max_indegree':\n",
    "    measures = np.array([max(value, 1e-3) for value in measures])\n",
    "    measures = np.log10(measures)\n",
    "\n",
    "\n",
    "if measure_type == 'nw_size':\n",
    "    measure_type = 'Network size (Log)'\n",
    "elif measure_type == 'nw_in_degree_centrality_gini':\n",
    "    measure_type = 'Gini coef of indegree centrality'\n",
    "    #measure_type = 'Gini indegree centrality'\n",
    "elif measure_type == 'nw_closeness_centrality_gini':\n",
    "    measure_type = 'Gini coef of closeness centrality'\n",
    "    #measure_type = 'Gini closeness centrality'\n",
    "elif measure_type == 'global_efficiency':\n",
    "    measure_type = 'Global efficiency'\n",
    "elif measure_type == 'nw_density':\n",
    "    measure_type = 'Network density'\n",
    "\n",
    "data_dict = {'Leaning': leanings, 'Topic': topics, measure_type: measures}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "#df.to_csv('siqi_plot/{}.csv'.format('nw_global_efficiency'), index=False)\n",
    "\n",
    "\n",
    "'''\n",
    "ax = sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips, \n",
    "                    palette=\"Set2\", split=True, scale=\"count\", inner=\"quartile\")\n",
    "'''\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "\n",
    "'''\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 16, \n",
    "    'axes.titlesize': 12, 'xtick.labelsize': 16, 'ytick.labelsize': 12}\n",
    "'''\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 22,\n",
    "    'axes.titlesize': 20, 'xtick.labelsize': 18, 'ytick.labelsize': 20}\n",
    "\n",
    "#plt.rcParams.update(**rc)\n",
    "sns.set(rc=rc)\n",
    "sns.set_style(style='white')\n",
    "\n",
    "#sns.set(font_scale = 1.1)\n",
    "#colors = [\"#7DA2DB\", \"#D17475\"]\n",
    "#customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "ax = sns.violinplot(x=\"Topic\", y=measure_type, hue=\"Leaning\", data=df, \n",
    "                    palette={\"Right\": \"#e06666\", \"Left\": \"#6d9eeb\"}, split=True, inner=\"quartile\")\n",
    "\n",
    "\n",
    "if measure_type == 'Gini indegree centrality' or measure_type == 'Gini closeness centrality':\n",
    "    ax.set(ylim=(0, 1.1))\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "\n",
    "if measure_type == 'Network size (Log)':\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(exponent_fmt))\n",
    "\n",
    "ax.legend(loc='lower center', frameon=False, fontsize=16)\n",
    "#ax.spines['center'].set_visible(False)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "\n",
    "#ax.get_legend().set_visible(False)\n",
    "\n",
    "#plt.savefig(\"nw_indegree_centrality_gini.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORAL MEASURE OPERATIONS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_measures_abo = tweet_abo.getAllTemporalMeasures(ea_tweets_abo)\n",
    "temporal_measures_gun = tweet_gun.getAllTemporalMeasures(ea_tweets_gun)\n",
    "temporal_measures_blm = tweet_blm.getAllTemporalMeasures(ea_tweets_blm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_type = 'nw_temporal_diff_between_pairs_mean'\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "measures_left_abo = [temporal_measures_abo[vid][measure_type] for vid in vids_abo['L']]\n",
    "measures_right_abo = [temporal_measures_abo[vid][measure_type] for vid in vids_abo['R']]\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_abo, measures_right_abo))\n",
    "print(pg.mwu(measures_left_abo, measures_right_abo, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_abo), np.median(measures_left_abo)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_abo), np.median(measures_right_abo)))\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "measures_left_gun = [temporal_measures_gun[vid][measure_type] for vid in vids_gun['L']]\n",
    "measures_right_gun = [temporal_measures_gun[vid][measure_type] for vid in vids_gun['R']]\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_gun, measures_right_gun))\n",
    "print(pg.mwu(measures_left_gun, measures_right_gun, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_gun), np.median(measures_left_gun)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_gun), np.median(measures_right_gun)))\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "measures_left_blm = [temporal_measures_blm[vid][measure_type] for vid in vids_blm['L']]\n",
    "measures_right_blm = [temporal_measures_blm[vid][measure_type] for vid in vids_blm['R']]\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_blm, measures_right_blm))\n",
    "print(pg.mwu(measures_left_blm, measures_right_blm, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_blm), np.median(measures_left_blm)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_blm), np.median(measures_right_blm)))\n",
    "\n",
    "leanings = ['Left']*len(measures_left_abo) + ['Right']*len(measures_right_abo) + ['Left']*len(measures_left_gun) + ['Right']*len(measures_right_gun) + ['Left']*len(measures_left_blm) + ['Right']*len(measures_right_blm) \n",
    "topics = ['Abortion']*(len(measures_left_abo)+len(measures_right_abo)) + ['Gun control']*(len(measures_left_gun)+len(measures_right_gun)) + ['BLM']*(len(measures_left_blm)+len(measures_right_blm))\n",
    "measures = measures_left_abo + measures_right_abo + measures_left_gun + measures_right_gun + measures_left_blm + measures_right_blm\n",
    "\n",
    "measures = np.array([max(value, 1e-3) for value in measures])\n",
    "measures = np.log10(measures)\n",
    "\n",
    "if measure_type == 'nw_temporal_diff_wrt_first_tweet_mean':\n",
    "    measure_type = 'Time delay (Log)'\n",
    "elif measure_type == 'nw_temporal_diff_between_pairs_mean':\n",
    "    #measure_type = 'Lag b/w consecutive tweets (Log)'\n",
    "    measure_type = 'Inter-arrival time (Log)'\n",
    "elif measure_type == 'nw_life_time':\n",
    "    measure_type = 'Lifetime (Log)'\n",
    "elif measure_type == 'nw_temporal_diff_between_first_tweets_of_source_users_mean':\n",
    "    measure_type = 'Lag b/w first tweets \\n of source users (Log)'\n",
    "elif measure_type == 'nw_temporal_diff_between_max_indegree_user':\n",
    "    measure_type = 'Lag between the first tweets of source users (Log)'\n",
    "\n",
    "data_dict = {'Leaning': leanings, 'Topic': topics, measure_type: measures}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "#df.to_csv('siqi_plot/{}.csv'.format('t_inter_arrival_time'), index=False)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "'''\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 16, \n",
    "    'axes.titlesize': 12, 'xtick.labelsize': 16, 'ytick.labelsize': 12}\n",
    "'''\n",
    "rc={'axes.labelsize': 20, 'legend.fontsize': 22,\n",
    "    'axes.titlesize': 22, 'xtick.labelsize': 18, 'ytick.labelsize': 20}\n",
    "\n",
    "sns.set(rc=rc)\n",
    "sns.set_style(style='white')\n",
    "\n",
    "ax = sns.violinplot(x=\"Topic\", y=measure_type, hue=\"Leaning\", data=df, \n",
    "                    palette={\"Right\": \"#e06666\", \"Left\": \"#6d9eeb\"}, split=True, inner=\"quartile\")\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(exponent_fmt))\n",
    "\n",
    "#ax.legend(loc='upper left', frameon=False, fontsize=16)\n",
    "#ax.spines['right'].set_visible(False)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "#plt.savefig(\"life_time.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENGAGEMENT MEASURE OPERATIONS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_measures_abo = tweet_abo.getAllEngagementMeasures(ea_tweets_abo)\n",
    "engagement_measures_gun = tweet_gun.getAllEngagementMeasures(ea_tweets_gun)\n",
    "engagement_measures_blm = tweet_blm.getAllEngagementMeasures(ea_tweets_blm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_type = 'num_tweets'\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "measures_left_abo = [engagement_measures_abo[vid][measure_type] for vid in vids_abo['L']]\n",
    "measures_right_abo = [engagement_measures_abo[vid][measure_type] for vid in vids_abo['R']]\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_abo, measures_right_abo))\n",
    "print(pg.mwu(measures_left_abo, measures_right_abo, tail='one-sided'))\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "measures_left_gun = [engagement_measures_gun[vid][measure_type] for vid in vids_gun['L']]\n",
    "measures_right_gun = [engagement_measures_gun[vid][measure_type] for vid in vids_gun['R']]\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_gun, measures_right_gun))\n",
    "print(pg.mwu(measures_left_gun, measures_right_gun, tail='one-sided'))\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "measures_left_blm = [engagement_measures_blm[vid][measure_type] for vid in vids_blm['L']]\n",
    "measures_right_blm = [engagement_measures_blm[vid][measure_type] for vid in vids_blm['R']]\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_blm, measures_right_blm))\n",
    "print(pg.mwu(measures_left_blm, measures_right_blm, tail='one-sided'))\n",
    "\n",
    "leanings = ['Left']*len(measures_left_abo) + ['Right']*len(measures_right_abo) + ['Left']*len(measures_left_gun) + ['Right']*len(measures_right_gun) + ['Left']*len(measures_left_blm) + ['Right']*len(measures_right_blm) \n",
    "topics = ['Abortion']*(len(measures_left_abo)+len(measures_right_abo)) + ['Gun control']*(len(measures_left_gun)+len(measures_right_gun)) + ['BLM']*(len(measures_left_blm)+len(measures_right_blm))\n",
    "measures = measures_left_abo + measures_right_abo + measures_left_gun + measures_right_gun + measures_left_blm + measures_right_blm\n",
    "\n",
    "measures = np.array([max(value, 1e-1) for value in measures])\n",
    "measures = np.log10(measures)\n",
    "\n",
    "if measure_type == 'num_tweets':\n",
    "    measure_type = '#total tweets (Log)'\n",
    "elif measure_type == 'num_original_tweets':\n",
    "    measure_type = '#original tweets (Log)'\n",
    "elif measure_type == 'num_quoted_tweets':\n",
    "    measure_type = '#quoted tweets (Log)'\n",
    "elif measure_type == 'num_retweets':\n",
    "    measure_type = '#retweets (Log)'\n",
    "elif measure_type == 'num_replies':\n",
    "    measure_type = '#replies (Log)'\n",
    "\n",
    "data_dict = {'Leaning': leanings, 'Topic': topics, measure_type: measures}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 16, \n",
    "    'axes.titlesize': 12, 'xtick.labelsize': 16, 'ytick.labelsize': 12}\n",
    "sns.set(rc=rc)\n",
    "sns.set_style(style='white')\n",
    "\n",
    "ax = sns.violinplot(x=\"Topic\", y=measure_type, hue=\"Leaning\", data=df, \n",
    "                    palette={\"Right\": \"#e06666\", \"Left\": \"#6d9eeb\"}, split=True, inner=\"quartile\")\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "ax.set(ylim=(0, None))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(exponent_fmt))\n",
    "\n",
    "ax.legend(loc='upper right', frameon=False, fontsize=16)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "#plt.savefig(\"num_replies.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOLLOWERS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_abo = pickle.load(open(tweet_abo.tweets_path, 'rb'))\n",
    "users_abo = pickle.load(open(tweet_abo.users_path, 'rb'))\n",
    "all_tweets_gun = pickle.load(open(tweet_gun.tweets_path, 'rb'))\n",
    "users_gun = pickle.load(open(tweet_gun.users_path, 'rb'))\n",
    "all_tweets_blm = pickle.load(open(tweet_blm.tweets_path, 'rb'))\n",
    "users_blm = pickle.load(open(tweet_blm.users_path, 'rb'))\n",
    "\n",
    "print(len(users_abo.keys()), len(users_gun.keys()), len(users_blm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure_type: [max | median | mean]\n",
    "measure_type = \"max\"\n",
    "\n",
    "#user_type: [EA | All]\n",
    "user_type = \"All\"\n",
    "tweets_abo = ea_tweets_abo if user_type == \"EA\" else all_tweets_abo\n",
    "tweets_gun = ea_tweets_gun if user_type == \"EA\" else all_tweets_gun\n",
    "tweets_blm = ea_tweets_blm if user_type == \"EA\" else all_tweets_blm\n",
    "\n",
    "followers_abo = {}\n",
    "for tid in tweets_abo:\n",
    "    uid = tweets_abo[tid]['_source']['user_id_str']\n",
    "    num_followers = int(users_abo[uid]['_source']['followers_count'])\n",
    "    original_video_ids = tweets_abo[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = tweets_abo[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = tweets_abo[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in followers_abo:\n",
    "            followers_abo[vid] = {}\n",
    "        followers_abo[vid][uid] = num_followers\n",
    "\n",
    "followers_gun = {}\n",
    "for tid in tweets_gun:\n",
    "    uid = tweets_gun[tid]['_source']['user_id_str']\n",
    "    num_followers = int(users_gun[uid]['_source']['followers_count'])\n",
    "    original_video_ids = tweets_gun[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = tweets_gun[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = tweets_gun[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in followers_gun:\n",
    "            followers_gun[vid] = {}\n",
    "        followers_gun[vid][uid] = num_followers\n",
    "\n",
    "followers_blm = {}\n",
    "for tid in tweets_blm:\n",
    "    uid = tweets_blm[tid]['_source']['user_id_str']\n",
    "    num_followers = int(users_blm[uid]['_source']['followers_count'])\n",
    "    original_video_ids = tweets_blm[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = tweets_blm[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = tweets_blm[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in followers_blm:\n",
    "            followers_blm[vid] = {}\n",
    "        followers_blm[vid][uid] = num_followers\n",
    "\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "if measure_type == \"max\":\n",
    "    measures_left_abo = [max(list(followers_abo[vid].values())) for vid in vids_abo['L']]\n",
    "    measures_right_abo = [max(list(followers_abo[vid].values())) for vid in vids_abo['R']]\n",
    "elif measure_type == \"median\":\n",
    "    measures_left_abo = [np.median(list(followers_abo[vid].values())) for vid in vids_abo['L']]\n",
    "    measures_right_abo = [np.median(list(followers_abo[vid].values())) for vid in vids_abo['R']]\n",
    "elif measure_type == \"mean\":\n",
    "    measures_left_abo = [np.mean(list(followers_abo[vid].values())) for vid in vids_abo['L']]\n",
    "    measures_right_abo = [np.mean(list(followers_abo[vid].values())) for vid in vids_abo['R']]\n",
    "\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_abo, measures_right_abo))\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "if measure_type == \"max\":\n",
    "    measures_left_gun = [max(list(followers_gun[vid].values())) for vid in vids_gun['L']]\n",
    "    measures_right_gun = [max(list(followers_gun[vid].values())) for vid in vids_gun['R']]\n",
    "elif measure_type == \"median\":\n",
    "    measures_left_gun = [np.median(list(followers_gun[vid].values())) for vid in vids_gun['L']]\n",
    "    measures_right_gun = [np.median(list(followers_gun[vid].values())) for vid in vids_gun['R']]\n",
    "elif measure_type == \"mean\":\n",
    "    measures_left_gun = [np.mean(list(followers_gun[vid].values())) for vid in vids_gun['L']]\n",
    "    measures_right_gun = [np.mean(list(followers_gun[vid].values())) for vid in vids_gun['R']]\n",
    "    \n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_gun, measures_right_gun))\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "if measure_type == \"max\":\n",
    "    measures_left_blm = [max(list(followers_blm[vid].values())) for vid in vids_blm['L']]\n",
    "    measures_right_blm = [max(list(followers_blm[vid].values())) for vid in vids_blm['R']]\n",
    "elif measure_type == \"median\":\n",
    "    measures_left_blm = [np.median(list(followers_blm[vid].values())) for vid in vids_blm['L']]\n",
    "    measures_right_blm = [np.median(list(followers_blm[vid].values())) for vid in vids_blm['R']]\n",
    "elif measure_type == \"mean\":\n",
    "    measures_left_blm = [np.mean(list(followers_blm[vid].values())) for vid in vids_blm['L']]\n",
    "    measures_right_blm = [np.mean(list(followers_blm[vid].values())) for vid in vids_blm['R']]\n",
    "    \n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_blm, measures_right_blm))\n",
    "\n",
    "leanings = ['Left']*len(measures_left_abo) + ['Right']*len(measures_right_abo) + ['Left']*len(measures_left_gun) + ['Right']*len(measures_right_gun) + ['Left']*len(measures_left_blm) + ['Right']*len(measures_right_blm) \n",
    "topics = ['Abortion']*(len(measures_left_abo)+len(measures_right_abo)) + ['Gun control']*(len(measures_left_gun)+len(measures_right_gun)) + ['BLM']*(len(measures_left_blm)+len(measures_right_blm))\n",
    "measures = measures_left_abo + measures_right_abo + measures_left_gun + measures_right_gun + measures_left_blm + measures_right_blm\n",
    "\n",
    "measures = np.array([max(value, 1e-3) for value in measures])\n",
    "measures = np.log10(measures)\n",
    "\n",
    "\n",
    "if measure_type == 'max':\n",
    "    measure_type = '#Followers (Max.)'\n",
    "elif measure_type == 'median':\n",
    "    measure_type = '#Followers (Median)'\n",
    "elif measure_type == 'mean':\n",
    "    measure_type = '#Followers (Mean)'\n",
    "\n",
    "data_dict = {'Leaning': leanings, 'Topic': topics, measure_type: measures}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 16, \n",
    "    'axes.titlesize': 12, 'xtick.labelsize': 16, 'ytick.labelsize': 12}\n",
    "sns.set(rc=rc)\n",
    "sns.set_style(style='white')\n",
    "\n",
    "ax = sns.violinplot(x=\"Topic\", y=measure_type, hue=\"Leaning\", data=df, \n",
    "                    palette={\"Right\": \"#e06666\", \"Left\": \"#6d9eeb\"}, split=True, inner=\"quartile\")\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(exponent_fmt))\n",
    "\n",
    "ax.legend(loc='upper right', frameon=False, fontsize=11)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "#plt.savefig(\"max_followers.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIDEO POLARITY, INTENSITY, DIVISIVENESS and POPULARITY ANALYSIS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_type = \"fraction_of_likes\"\n",
    "\n",
    "video_first_share_time_abo = {}\n",
    "for tid in ea_tweets_abo:\n",
    "    timestamp = int(ea_tweets_abo[tid]['_source']['timestamp_ms'])\n",
    "    original_video_ids = ea_tweets_abo[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = ea_tweets_abo[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = ea_tweets_abo[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in video_first_share_time_abo:\n",
    "            video_first_share_time_abo[vid] = timestamp\n",
    "        else:\n",
    "            if timestamp < video_first_share_time_abo[vid]:\n",
    "                video_first_share_time_abo[vid] = timestamp\n",
    "\n",
    "video_first_share_time_gun = {}\n",
    "for tid in ea_tweets_gun:\n",
    "    timestamp = int(ea_tweets_gun[tid]['_source']['timestamp_ms'])\n",
    "    original_video_ids = ea_tweets_gun[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = ea_tweets_gun[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = ea_tweets_gun[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in video_first_share_time_gun:\n",
    "            video_first_share_time_gun[vid] = timestamp\n",
    "        else:\n",
    "            if timestamp < video_first_share_time_gun[vid]:\n",
    "                video_first_share_time_gun[vid] = timestamp\n",
    "\n",
    "video_first_share_time_blm = {}\n",
    "for tid in ea_tweets_blm:\n",
    "    timestamp = int(ea_tweets_blm[tid]['_source']['timestamp_ms'])\n",
    "    original_video_ids = ea_tweets_blm[tid]['_source']['original_vids'].split(';')\n",
    "    retweeted_video_ids = ea_tweets_blm[tid]['_source']['retweeted_vids'].split(';')\n",
    "    quoted_video_ids = ea_tweets_blm[tid]['_source']['quoted_vids'].split(';')\n",
    "    video_ids = list(set(original_video_ids + retweeted_video_ids + quoted_video_ids))\n",
    "    if 'N' in video_ids:\n",
    "        video_ids.remove('N')\n",
    "    for vid in video_ids:\n",
    "        if vid not in video_first_share_time_blm:\n",
    "            video_first_share_time_blm[vid] = timestamp\n",
    "        else:\n",
    "            if timestamp < video_first_share_time_blm[vid]:\n",
    "                video_first_share_time_blm[vid] = timestamp\n",
    "\n",
    "videos_abo = pickle.load(open(tweet_abo.videos_path, 'rb'))\n",
    "video_props_abo = {}\n",
    "for vid in video_leanings_probs_abo:\n",
    "    video_props_abo[vid] = {}\n",
    "    like_count = int(videos_abo[vid]['_source']['statistics']['likeCount'])\n",
    "    dislike_count = int(videos_abo[vid]['_source']['statistics']['dislikeCount'])\n",
    "    view_count = int(videos_abo[vid]['_source']['statistics']['viewCount'])\n",
    "    first_share_time = video_first_share_time_abo[vid]\n",
    "    polarity, intensity, hostility, popularity = tweet_abo.util.calculateVideoScores(like_count, dislike_count, view_count, first_share_time)\n",
    "    video_props_abo[vid]['like_count'] = like_count\n",
    "    video_props_abo[vid]['dislike_count'] = dislike_count\n",
    "    video_props_abo[vid]['view_count'] = view_count\n",
    "    video_props_abo[vid]['polarity'] = polarity\n",
    "    video_props_abo[vid]['intensity'] = intensity\n",
    "    video_props_abo[vid]['hostility'] = hostility\n",
    "    video_props_abo[vid]['popularity'] = popularity\n",
    "    video_props_abo[vid]['fraction_of_likes'] = (1 - (hostility+0.5))\n",
    "\n",
    "videos_gun = pickle.load(open(tweet_gun.all_videos_from_annotated_videos_path, 'rb'))\n",
    "video_props_gun = {}\n",
    "for vid in video_leanings_probs_gun:\n",
    "    video_props_gun[vid] = {}\n",
    "    like_count = int(videos_gun[vid]['_source']['statistics']['likeCount'])\n",
    "    dislike_count = int(videos_gun[vid]['_source']['statistics']['dislikeCount'])\n",
    "    view_count = int(videos_gun[vid]['_source']['statistics']['viewCount'])\n",
    "    first_share_time = video_first_share_time_gun[vid]\n",
    "    polarity, intensity, hostility, popularity = tweet_gun.util.calculateVideoScores(like_count, dislike_count, view_count, first_share_time)\n",
    "    video_props_gun[vid]['like_count'] = like_count\n",
    "    video_props_gun[vid]['dislike_count'] = dislike_count\n",
    "    video_props_gun[vid]['view_count'] = view_count\n",
    "    video_props_gun[vid]['polarity'] = polarity\n",
    "    video_props_gun[vid]['intensity'] = intensity\n",
    "    video_props_gun[vid]['hostility'] = hostility\n",
    "    video_props_gun[vid]['popularity'] = popularity\n",
    "    video_props_gun[vid]['fraction_of_likes'] = (1 - (hostility+0.5))\n",
    "\n",
    "videos_blm = pickle.load(open(tweet_blm.all_videos_from_annotated_videos_path, 'rb'))\n",
    "video_props_blm = {}\n",
    "for vid in video_leanings_probs_blm:\n",
    "    video_props_blm[vid] = {}\n",
    "    like_count = int(videos_blm[vid]['_source']['statistics']['likeCount'])\n",
    "    dislike_count = int(videos_blm[vid]['_source']['statistics']['dislikeCount'])\n",
    "    view_count = int(videos_blm[vid]['_source']['statistics']['viewCount'])\n",
    "    first_share_time = video_first_share_time_blm[vid]\n",
    "    polarity, intensity, hostility, popularity = tweet_blm.util.calculateVideoScores(like_count, dislike_count, view_count, first_share_time)\n",
    "    video_props_blm[vid]['like_count'] = like_count\n",
    "    video_props_blm[vid]['dislike_count'] = dislike_count\n",
    "    video_props_blm[vid]['view_count'] = view_count\n",
    "    video_props_blm[vid]['polarity'] = polarity\n",
    "    video_props_blm[vid]['intensity'] = intensity\n",
    "    video_props_blm[vid]['hostility'] = hostility\n",
    "    video_props_blm[vid]['popularity'] = popularity\n",
    "    video_props_blm[vid]['fraction_of_likes'] = (1 - (hostility+0.5))\n",
    "\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "measures_left_abo = [video_props_abo[vid][measure_type] for vid in vids_abo['L']]\n",
    "measures_right_abo = [video_props_abo[vid][measure_type] for vid in vids_abo['R']]\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_abo, measures_right_abo, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_abo, measures_right_abo))\n",
    "#print(len(measures_left_abo), len(measures_right_abo))\n",
    "print(pg.mwu(measures_left_abo, measures_right_abo, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_abo), np.median(measures_left_abo)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_abo), np.median(measures_right_abo)))\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "measures_left_gun = [video_props_gun[vid][measure_type] for vid in vids_gun['L']]\n",
    "measures_right_gun = [video_props_gun[vid][measure_type] for vid in vids_gun['R']]\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_gun, measures_right_gun, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_gun, measures_right_gun))\n",
    "#print(len(measures_left_gun), len(measures_right_gun))\n",
    "print(pg.mwu(measures_left_gun, measures_right_gun, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_gun), np.median(measures_left_gun)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_gun), np.median(measures_right_gun)))\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "measures_left_blm = [video_props_blm[vid][measure_type] for vid in vids_blm['L']]\n",
    "measures_right_blm = [video_props_blm[vid][measure_type] for vid in vids_blm['R']]\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='less'))\n",
    "print(mannwhitneyu(measures_left_blm, measures_right_blm, alternative='two-sided'))\n",
    "print(ks_2samp(measures_left_blm, measures_right_blm))\n",
    "#print(len(measures_left_blm), len(measures_right_blm))\n",
    "print(pg.mwu(measures_left_blm, measures_right_blm, tail='one-sided'))\n",
    "print('Left -- mean: {}, median: {}'.format(np.mean(measures_left_blm), np.median(measures_left_blm)))\n",
    "print('Right -- mean: {}, median: {}'.format(np.mean(measures_right_blm), np.median(measures_right_blm)))\n",
    "\n",
    "leanings = ['Left']*len(measures_left_abo) + ['Right']*len(measures_right_abo) + ['Left']*len(measures_left_gun) + ['Right']*len(measures_right_gun) + ['Left']*len(measures_left_blm) + ['Right']*len(measures_right_blm) \n",
    "topics = ['Abortion']*(len(measures_left_abo)+len(measures_right_abo)) + ['Gun control']*(len(measures_left_gun)+len(measures_right_gun)) + ['BLM']*(len(measures_left_blm)+len(measures_right_blm))\n",
    "measures = measures_left_abo + measures_right_abo + measures_left_gun + measures_right_gun + measures_left_blm + measures_right_blm\n",
    "\n",
    "if measure_type == 'polarity':\n",
    "    measure_type = 'Polarity'\n",
    "elif measure_type == 'intensity':\n",
    "    measure_type = 'Intensity'\n",
    "elif measure_type == 'hostility':\n",
    "    measure_type = 'Hostility'\n",
    "elif measure_type == 'fraction_of_likes':\n",
    "    measure_type = 'Fraction of likes'\n",
    "\n",
    "data_dict = {'Leaning': leanings, 'Topic': topics, measure_type: measures}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df.to_csv('siqi_plot/{}.csv'.format('yt_fraction_of_likes'), index=False)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "\n",
    "'''\n",
    "rc={'axes.labelsize': 16, 'legend.fontsize': 16, \n",
    "    'axes.titlesize': 12, 'xtick.labelsize': 16, 'ytick.labelsize': 12}\n",
    "'''\n",
    "rc={'axes.labelsize': 22, 'legend.fontsize': 22,\n",
    "    'axes.titlesize': 22, 'xtick.labelsize': 22, 'ytick.labelsize': 20}\n",
    "\n",
    "sns.set(rc=rc)\n",
    "sns.set_style(style='white')\n",
    "\n",
    "ax = sns.violinplot(x=\"Topic\", y=measure_type, hue=\"Leaning\", data=df, \n",
    "                    palette={\"Right\": \"#e06666\", \"Left\": \"#6d9eeb\"}, split=True, inner=\"quartile\")\n",
    "\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "ax.set_title('(e)', pad=-3.7 * 72, y=1)\n",
    "\n",
    "if measure_type == 'Hostility':\n",
    "    ax.set(ylim=(-0.55, 0.55))\n",
    "elif measure_type == 'Fraction of Likes':\n",
    "    ax.set(ylim=(0, 1.1))\n",
    "elif measure_type == 'Intensity':\n",
    "    ax.set(ylim=(0, None))\n",
    "elif measure_type == 'Polarity':\n",
    "    ax.set(ylim=(0, 1.1))\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles[0:], labels=labels[0:])\n",
    "\n",
    "#ax.legend(loc='upper right', frameon=False, fontsize=11)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "#ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "#plt.savefig(\"youtube_reactions_{}.pdf\".format(measure_type), bbox_inches = 'tight', pad_inches = 0, dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify locations of users and tweets in state-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_abo = pickle.load(open(tweet_abo.tweets_path, 'rb'))\n",
    "all_users_locs_abo = pickle.load(open(tweet_abo.users_locs_path, 'rb'))\n",
    "ea_users_locs_abo = pickle.load(open(tweet_abo.ea_users_locs_path, 'rb'))\n",
    "\n",
    "all_tweets_gun = pickle.load(open(tweet_gun.tweets_path, 'rb'))\n",
    "all_users_locs_gun = pickle.load(open(tweet_gun.users_locs_path, 'rb'))\n",
    "ea_users_locs_gun = pickle.load(open(tweet_gun.ea_users_locs_path, 'rb'))\n",
    "\n",
    "\n",
    "all_tweets_blm = pickle.load(open(tweet_blm.tweets_path, 'rb'))\n",
    "all_users_locs_blm = pickle.load(open(tweet_blm.users_locs_path, 'rb'))\n",
    "ea_users_locs_blm = pickle.load(open(tweet_blm.ea_users_locs_path, 'rb'))\n",
    "\n",
    "states = location.getStates()\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_type: [EA | All]\n",
    "user_type = \"All\"\n",
    "tweets_abo = ea_tweets_abo if user_type == \"EA\" else all_tweets_abo\n",
    "tweets_gun = ea_tweets_gun if user_type == \"EA\" else all_tweets_gun\n",
    "tweets_blm = ea_tweets_blm if user_type == \"EA\" else all_tweets_blm\n",
    "\n",
    "users_locs_abo = ea_users_locs_abo if user_type == \"EA\" else all_users_locs_abo\n",
    "users_locs_gun = ea_users_locs_gun if user_type == \"EA\" else all_users_locs_gun\n",
    "users_locs_blm = ea_users_locs_blm if user_type == \"EA\" else all_users_locs_blm\n",
    "\n",
    "abo_loc_tweets = 0\n",
    "abo_loc_users = set()\n",
    "abo_users = set()\n",
    "for tid in tweets_abo:\n",
    "    uid = tweets_abo[tid]['_source']['user_id_str']\n",
    "    loc = users_locs_abo[uid]\n",
    "    if loc != None and loc in states:\n",
    "        abo_loc_tweets += 1\n",
    "        abo_loc_users.add(uid)\n",
    "    abo_users.add(uid)\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "print(\"{}/{} tweets {}/{} unique users with ratio {} and {}, respectively.\".format(abo_loc_tweets, \n",
    "                                                                                  len(tweets_abo.keys()), \n",
    "                                                                                  len(abo_loc_users),\n",
    "                                                                                  len(abo_users), \n",
    "                                                                                  float(abo_loc_tweets) / len(tweets_abo.keys()), \n",
    "                                                                                  float(len(abo_loc_users)) / len(abo_users)))\n",
    "\n",
    "gun_loc_tweets = 0\n",
    "gun_loc_users = set()\n",
    "gun_users = set()\n",
    "for tid in tweets_gun:\n",
    "    uid = tweets_gun[tid]['_source']['user_id_str']\n",
    "    loc = users_locs_gun[uid]\n",
    "    if loc != None and loc in states:\n",
    "        gun_loc_tweets += 1\n",
    "        gun_loc_users.add(uid)\n",
    "    gun_users.add(uid)\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "print(\"{}/{} tweets {}/{} unique users with ratio {} and {}, respectively.\".format(gun_loc_tweets, \n",
    "                                                                                  len(tweets_gun.keys()), \n",
    "                                                                                  len(gun_loc_users),\n",
    "                                                                                  len(gun_users), \n",
    "                                                                                  float(gun_loc_tweets) / len(tweets_gun.keys()), \n",
    "                                                                                  float(len(gun_loc_users)) / len(gun_users)))\n",
    "\n",
    "blm_loc_tweets = 0\n",
    "blm_loc_users = set()\n",
    "blm_users = set()\n",
    "for tid in tweets_blm:\n",
    "    uid = tweets_blm[tid]['_source']['user_id_str']\n",
    "    loc = users_locs_blm[uid]\n",
    "    if loc != None and loc in states:\n",
    "        blm_loc_tweets += 1\n",
    "        blm_loc_users.add(uid)\n",
    "    blm_users.add(uid)\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "print(\"{}/{} tweets {}/{} unique users with ratio {} and {}, respectively.\".format(blm_loc_tweets, \n",
    "                                                                                  len(tweets_blm.keys()), \n",
    "                                                                                  len(blm_loc_users),\n",
    "                                                                                  len(blm_users), \n",
    "                                                                                  float(blm_loc_tweets) / len(tweets_blm.keys()), \n",
    "                                                                                  float(len(blm_loc_users)) / len(blm_users)))\n",
    "\n",
    "print(len(abo_users), len(gun_users), len(blm_users))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag Analysis in User Profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_abo = pickle.load(open(tweet_abo.ea_users_ids_path, 'rb'))\n",
    "users_abo = pickle.load(open(tweet_abo.users_path, 'rb'))\n",
    "\n",
    "user_ids_gun = pickle.load(open(tweet_gun.ea_users_ids_path, 'rb'))\n",
    "users_gun = pickle.load(open(tweet_gun.users_path, 'rb'))\n",
    "\n",
    "user_ids_blm = pickle.load(open(tweet_blm.ea_users_ids_path, 'rb'))\n",
    "users_blm = pickle.load(open(tweet_blm.users_path, 'rb'))\n",
    "\n",
    "\n",
    "left_hts_abo = []\n",
    "with open(tweet_abo.left_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    left_hts_abo = [ht.rstrip() for ht in inp]\n",
    "\n",
    "right_hts_abo = []\n",
    "with open(tweet_abo.right_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    right_hts_abo = [ht.rstrip() for ht in inp]    \n",
    "\n",
    "abo_users_leaning_hashtags = {}\n",
    "abo_users_all_hashtags = {}\n",
    "for user_id in user_ids_abo:\n",
    "    user_desc = users_abo[user_id]['_source']['description']\n",
    "    user_hashtags = list(set(re.findall(r\"#(\\w+)\", user_desc)))\n",
    "    user_hashtags = [tag.lower() for tag in user_hashtags]\n",
    "    abo_users_all_hashtags[user_id] = len(user_hashtags)\n",
    "    cnt = 0\n",
    "    if len(set(user_hashtags).intersection(set(left_hts_abo+right_hts_abo))) > 0:\n",
    "        for ht in user_hashtags:\n",
    "            if ht in left_hts_abo or ht in right_hts_abo:\n",
    "                cnt+=1\n",
    "        abo_users_leaning_hashtags[user_id] = cnt\n",
    "    '''\n",
    "    for ht in user_hashtags:\n",
    "        if ht in left_hts_abo or ht in right_hts_abo:\n",
    "            cnt+=1\n",
    "    abo_users_leaning_hashtags[user_id] = cnt\n",
    "    '''\n",
    "\n",
    "print(\">>> ABO >>>\")\n",
    "print(\"leaning hashtags per profile: {}, all hashtags per profile {}\".format(sum(list(abo_users_leaning_hashtags.values())) / len(abo_users_leaning_hashtags.values()), \n",
    "                                                                             sum(list(abo_users_all_hashtags.values())) / len(abo_users_all_hashtags.values())))\n",
    "\n",
    "print(\"#seed users: {}\".format(len(abo_users_leaning_hashtags.keys())))\n",
    "\n",
    "left_hts_gun = []\n",
    "with open(tweet_gun.left_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    left_hts_gun = [ht.rstrip() for ht in inp]\n",
    "\n",
    "right_hts_gun = []\n",
    "with open(tweet_gun.right_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    right_hts_gun = [ht.rstrip() for ht in inp]  \n",
    "\n",
    "gun_users_leaning_hashtags = {}\n",
    "gun_users_all_hashtags = {}\n",
    "for user_id in user_ids_gun:\n",
    "    user_desc = users_gun[user_id]['_source']['description']\n",
    "    user_hashtags = list(set(re.findall(r\"#(\\w+)\", user_desc)))\n",
    "    user_hashtags = [tag.lower() for tag in user_hashtags]\n",
    "    gun_users_all_hashtags[user_id] = len(user_hashtags)\n",
    "    cnt = 0\n",
    "    if len(set(user_hashtags).intersection(set(left_hts_gun+right_hts_gun))) > 0:\n",
    "        for ht in user_hashtags:\n",
    "            if ht in left_hts_gun or ht in right_hts_gun:\n",
    "                cnt+=1\n",
    "        gun_users_leaning_hashtags[user_id] = cnt\n",
    "    '''\n",
    "    for ht in user_hashtags:\n",
    "        if ht in left_hts_gun or ht in right_hts_gun:\n",
    "            cnt+=1\n",
    "    gun_users_leaning_hashtags[user_id] = cnt\n",
    "    '''\n",
    "\n",
    "print(\">>> GUN >>>\")\n",
    "print(\"leaning hashtags per profile: {}, all hashtags per profile {}\".format(sum(list(gun_users_leaning_hashtags.values())) / len(gun_users_leaning_hashtags.values()), \n",
    "                                                                             sum(list(gun_users_all_hashtags.values())) / len(gun_users_all_hashtags.values())))\n",
    "\n",
    "print(\"#seed users: {}\".format(len(gun_users_leaning_hashtags.keys())))\n",
    "\n",
    "left_hts_blm = []\n",
    "with open(tweet_blm.left_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    left_hts_blm = [ht.rstrip() for ht in inp]\n",
    "\n",
    "right_hts_blm = []\n",
    "with open(tweet_blm.right_extended_political_hashtags_path, 'r') as f:\n",
    "    inp = f.readlines()\n",
    "    right_hts_blm = [ht.rstrip() for ht in inp] \n",
    "\n",
    "blm_users_leaning_hashtags = {}\n",
    "blm_users_all_hashtags = {}\n",
    "for user_id in user_ids_blm:\n",
    "    user_desc = users_blm[user_id]['_source']['description']\n",
    "    user_hashtags = list(set(re.findall(r\"#(\\w+)\", user_desc)))\n",
    "    user_hashtags = [tag.lower() for tag in user_hashtags]\n",
    "    blm_users_all_hashtags[user_id] = len(user_hashtags)\n",
    "    cnt = 0\n",
    "    if len(set(user_hashtags).intersection(set(left_hts_blm+right_hts_blm))) > 0:\n",
    "        for ht in user_hashtags:\n",
    "            if ht in left_hts_blm or ht in right_hts_blm:\n",
    "                cnt+=1\n",
    "        blm_users_leaning_hashtags[user_id] = cnt\n",
    "    \n",
    "    '''\n",
    "    for ht in user_hashtags:\n",
    "        if ht in left_hts_blm or ht in right_hts_blm:\n",
    "            cnt+=1\n",
    "    blm_users_leaning_hashtags[user_id] = cnt\n",
    "    '''\n",
    "\n",
    "\n",
    "print(\">>> BLM >>>\")\n",
    "print(\"leaning hashtags per profile: {}, all hashtags per profile {}\".format(sum(list(blm_users_leaning_hashtags.values())) / len(blm_users_leaning_hashtags.values()), \n",
    "                                                                             sum(list(blm_users_all_hashtags.values())) / len(blm_users_all_hashtags.values())))\n",
    "print(\"#seed users: {}\".format(len(blm_users_leaning_hashtags.keys())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
